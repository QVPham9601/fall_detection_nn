{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'DeepCNN' from 'd:\\\\4IF\\\\Stage\\\\Projet_stage\\\\fall-detection-pytorch\\\\DeepCNN.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import List_to_Pytorch_Dataset\n",
    "import importlib\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import CNN1D\n",
    "import Smaller_input_CNN\n",
    "import Neural_Networks\n",
    "from statistics import mean\n",
    "importlib.reload(List_to_Pytorch_Dataset)\n",
    "importlib.reload(DeepCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD 180\n",
      "WAL 183\n",
      "JOG 183\n",
      "JUM 183\n",
      "STU 200\n",
      "STN 200\n",
      "SCH 200\n",
      "SIT 190\n",
      "CHU 114\n",
      "CSI 200\n",
      "CSO 197\n",
      "FOL 192\n",
      "FKL 192\n",
      "BSC 191\n",
      "SDL 192\n"
     ]
    }
   ],
   "source": [
    "dataset = List_to_Pytorch_Dataset.MobifallData(augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2797\n",
      "Data sample size: 250\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Data sample size: {len(dataset[0][0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu' #cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = { 0  : \"STD\",\n",
    "           1  : \"WAL\",\n",
    "           2  : \"JOG\",\n",
    "           3  : \"JUM\",\n",
    "           4  : \"STU\",\n",
    "           5  : \"STN\",\n",
    "           6  : \"SCH\",\n",
    "           7  : \"SIT\",\n",
    "           8  : \"CHU\",\n",
    "           9  : \"CSI\",\n",
    "           10 : \"CSO\",\n",
    "           11 : \"FOL\",\n",
    "           12 : \"FKL\",\n",
    "           13 : \"BSC\",\n",
    "           14 : \"SDL\"\n",
    "           #15 : \"PFF\"\n",
    "           }\n",
    "\n",
    "classification_map = {}\n",
    "classification_map[\"Falls\"] = {\"TP\" : 0,\n",
    "                                 \"FP\" : 0,\n",
    "                                 \"TN\" : 0,\n",
    "                                 \"FN\" : 0}\n",
    "for key, value in labels.items():\n",
    "    classification_map[value] = {\"TP\" : 0,\n",
    "                                 \"FP\" : 0,\n",
    "                                 \"TN\" : 0,\n",
    "                                 \"FN\" : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch%10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fall(label):\n",
    "    return label in [11, 12, 13, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "\n",
    "            for key, value in labels.items():\n",
    "                for i in range(len(y)):\n",
    "                    if y[i] == key:\n",
    "                        if pred[i].argmax() == key:\n",
    "                            classification_map[value][\"TP\"] += 1\n",
    "                        else:\n",
    "                            classification_map[value][\"FN\"] += 1\n",
    "                    elif pred[i].argmax() == key:\n",
    "                        classification_map[value][\"FP\"] += 1\n",
    "                    else:\n",
    "                        classification_map[value][\"TN\"] += 1\n",
    "                        \n",
    "            #this is for fall/not-fall classification\n",
    "            for i in range(len(y)):\n",
    "                if is_fall(y[i]):\n",
    "                    if is_fall(pred[i].argmax()):\n",
    "                        classification_map[\"Falls\"][\"TP\"] += 1\n",
    "                    else:\n",
    "                        classification_map[\"Falls\"][\"FN\"] += 1\n",
    "                elif is_fall(pred[i].argmax()):\n",
    "                    classification_map[\"Falls\"][\"FP\"] += 1\n",
    "                else:\n",
    "                    classification_map[\"Falls\"][\"TN\"] += 1\n",
    "                    \n",
    "\n",
    "            #model loss and accuracy\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    #model stats\n",
    "    valid_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\\n\")\n",
    "    return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = DeepCNN.CNN().to(device)\n",
    "    model.train()\n",
    "\n",
    "    #this is for mobile use adaptation\n",
    "    #backend = \"qnnpack\"\n",
    "    #model.qconfig = torch.quantization.get_default_qat_qconfig(backend)\n",
    "    #model = torch.quantization.prepare_qat(model, inplace=False)\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    epochs = 40\n",
    "\n",
    "    # Initialize the loss function and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #creating datasets\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "\n",
    "    #Dataloaders for the datasets\n",
    "    train_dataloader = DataLoader(train_set, batch_size = 64, shuffle = True)\n",
    "    test_dataloader = DataLoader(test_set, batch_size = 64, shuffle = True)\n",
    "    \n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        print(i)\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    \n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "\n",
    "    model = torch.quantization.convert(model.eval(), inplace=False)\n",
    "    model_accuracy = valid_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "    return model, model_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 12, 3], expected input[64, 6, 250] to have 12 channels, but got 6 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model_accuracies \u001b[39m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[39m#for _ in range(5):\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m result \u001b[39m=\u001b[39m main()\n\u001b[0;32m      7\u001b[0m model \u001b[39m=\u001b[39m result[\u001b[39m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m model_accuracy \u001b[39m=\u001b[39m result[\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[22], line 30\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(i)\n\u001b[1;32m---> 30\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer)\n\u001b[0;32m     32\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m     33\u001b[0m model\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Compute prediction and loss\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m      8\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\4IF\\Stage\\Projet_stage\\fall-detection-pytorch\\DeepCNN.py:62\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):     \n\u001b[0;32m     60\u001b[0m     \u001b[39m#x = self.quant(x)\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)\n\u001b[0;32m     63\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(out)\n\u001b[0;32m     64\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(out)\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\PQV\\anaconda3\\envs\\fl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 12, 3], expected input[64, 6, 250] to have 12 channels, but got 6 channels instead"
     ]
    }
   ],
   "source": [
    "model_accuracy = 0\n",
    "while model_accuracy < 90:\n",
    "    metric_list = []\n",
    "    model_accuracies = []\n",
    "    #for _ in range(5):\n",
    "    result = main()\n",
    "    model = result[0]\n",
    "    model_accuracy = result[1]\n",
    "    if model_accuracy < 90:\n",
    "        continue\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    stats_map = {}\n",
    "    for key, value in classification_map.items():\n",
    "        stats_map[key] = {\n",
    "            \"Specificity\" : float(classification_map[key][\"TN\"]) / float(classification_map[key][\"TN\"] + classification_map[key][\"FP\"]),\n",
    "            \"Recall\" : float(classification_map[key][\"TP\"]) / float(classification_map[key][\"TP\"] + classification_map[key][\"FN\"]),\n",
    "            \"Precision\" : float(classification_map[key][\"TP\"]) / float(classification_map[key][\"TP\"] + classification_map[key][\"FP\"]),\n",
    "            \"Accuracy\" : float(classification_map[key][\"TP\"] + classification_map[key][\"TN\"]) / float(classification_map[key][\"TP\"] + classification_map[key][\"TN\"] + classification_map[key][\"FP\"] + classification_map[key][\"FN\"])\n",
    "        }\n",
    "        stats_map[key][\"F-score\"] = 2.0 / float((1.0 / float(stats_map[key][\"Precision\"])) + (1.0 / float(stats_map[key][\"Recall\"])))\n",
    "    metric_list.append(stats_map)\n",
    "    for key, value in classification_map.items():\n",
    "        classification_map[key] = {\"TP\" : 0,\n",
    "                                \"FP\" : 0,\n",
    "                                \"TN\" : 0,\n",
    "                                \"FN\" : 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity of Falls: 0.9922077922077922\n",
      "Recall of Falls: 0.9942857142857143\n",
      "Precision of Falls: 0.9830508474576272\n",
      "F1-score of Falls: 0.9886363636363635\n",
      "\n",
      "Specificity of FOL: 0.9980806142034548\n",
      "Recall of FOL: 0.8974358974358975\n",
      "Precision of FOL: 0.9722222222222222\n",
      "F1-score of FOL: 0.9333333333333331\n",
      "\n",
      "Specificity of FKL: 0.9961464354527938\n",
      "Recall of FKL: 0.8292682926829268\n",
      "Precision of FKL: 0.9444444444444444\n",
      "F1-score of FKL: 0.8831168831168832\n",
      "\n",
      "Specificity of BSC: 0.9921104536489151\n",
      "Recall of BSC: 0.9056603773584906\n",
      "Precision of BSC: 0.9230769230769231\n",
      "F1-score of BSC: 0.9142857142857143\n",
      "\n",
      "Specificity of SDL: 0.9768339768339769\n",
      "Recall of SDL: 0.9761904761904762\n",
      "Precision of SDL: 0.7735849056603774\n",
      "F1-score of SDL: 0.8631578947368421\n",
      "\n",
      "Model accuracy: 93.92857142857143\n"
     ]
    }
   ],
   "source": [
    "for key, value in metric_list[0].items():\n",
    "    if key == \"FOL\" or key ==\"FKL\" or key == \"BSC\" or key ==\"SDL\" or key ==\"Falls\":\n",
    "        specificity = mean([elem[key][\"Specificity\"] for elem in metric_list])\n",
    "        recall = mean([elem[key][\"Recall\"] for elem in metric_list])\n",
    "        precision = mean([elem[key][\"Precision\"] for elem in metric_list])\n",
    "        fScore = mean([elem[key][\"F-score\"] for elem in metric_list])\n",
    "        print(\"Specificity of \" + key + \": \" + str(specificity))\n",
    "        print(\"Recall of \" + key + \": \" + str(recall))\n",
    "        print(\"Precision of \" + key + \": \" + str(precision))\n",
    "        print(\"F1-score of \" + key + \": \" + str(fScore))\n",
    "        print(\"\")\n",
    "print(\"Model accuracy: \" + str(mean(model_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "def save_model(model):\n",
    "    torchscript_model = torch.jit.script(model)\n",
    "    torchscript_model_optimized = optimize_for_mobile(torchscript_model)\n",
    "    torch.jit.save(torchscript_model_optimized, \"MIS_RFD_model_quantized.pt\")\n",
    "    #torchscript_model_optimized._save_for_lite_interpreter(\"MIS_RFD_model_quantized.ptl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e29914317381cb5b054684ec136cf5f9d23d3fafddd70669a3da3e14954aacc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
